{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7823432,"sourceType":"datasetVersion","datasetId":4584064},{"sourceId":7831494,"sourceType":"datasetVersion","datasetId":4589786}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport torch\nimport torch.nn as nn\nimport sys","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-14T18:14:50.600442Z","iopub.execute_input":"2024-03-14T18:14:50.600738Z","iopub.status.idle":"2024-03-14T18:14:56.214227Z","shell.execute_reply.started":"2024-03-14T18:14:50.600714Z","shell.execute_reply":"2024-03-14T18:14:56.213397Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/training-data-meta-model/training_data_meta.csv')\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:14:56.215781Z","iopub.execute_input":"2024-03-14T18:14:56.216179Z","iopub.status.idle":"2024-03-14T18:14:56.738833Z","shell.execute_reply.started":"2024-03-14T18:14:56.216154Z","shell.execute_reply":"2024-03-14T18:14:56.737922Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"        training_instance  model_id   seizure       lpd       gpd      lrda  \\\n0                     0.0       0.0  0.987942  0.001896  0.000311  0.001601   \n1                     0.0       1.0  0.953424  0.010766  0.009874  0.009344   \n2                     0.0       2.0  0.999028  0.000045  0.000100  0.000110   \n3                     0.0       3.0  0.996094  0.000800  0.000262  0.001422   \n4                     0.0       4.0  0.684275  0.012821  0.022669  0.070409   \n...                   ...       ...       ...       ...       ...       ...   \n167065            11137.0      10.0  0.001482  0.028740  0.001911  0.620885   \n167066            11137.0      11.0  0.000743  0.000828  0.000018  0.950585   \n167067            11137.0      12.0  0.000651  0.003874  0.000048  0.919886   \n167068            11137.0      13.0  0.000248  0.000262  0.000013  0.988694   \n167069            11137.0      14.0  0.000418  0.001253  0.000038  0.938457   \n\n            grda     other  \n0       0.000568  0.007682  \n1       0.002544  0.014048  \n2       0.000053  0.000663  \n3       0.000122  0.001300  \n4       0.076193  0.133634  \n...          ...       ...  \n167065  0.087431  0.259551  \n167066  0.001804  0.046022  \n167067  0.003284  0.072257  \n167068  0.002034  0.008749  \n167069  0.022952  0.036882  \n\n[167070 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_instance</th>\n      <th>model_id</th>\n      <th>seizure</th>\n      <th>lpd</th>\n      <th>gpd</th>\n      <th>lrda</th>\n      <th>grda</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.987942</td>\n      <td>0.001896</td>\n      <td>0.000311</td>\n      <td>0.001601</td>\n      <td>0.000568</td>\n      <td>0.007682</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.953424</td>\n      <td>0.010766</td>\n      <td>0.009874</td>\n      <td>0.009344</td>\n      <td>0.002544</td>\n      <td>0.014048</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.999028</td>\n      <td>0.000045</td>\n      <td>0.000100</td>\n      <td>0.000110</td>\n      <td>0.000053</td>\n      <td>0.000663</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.996094</td>\n      <td>0.000800</td>\n      <td>0.000262</td>\n      <td>0.001422</td>\n      <td>0.000122</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.684275</td>\n      <td>0.012821</td>\n      <td>0.022669</td>\n      <td>0.070409</td>\n      <td>0.076193</td>\n      <td>0.133634</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>167065</th>\n      <td>11137.0</td>\n      <td>10.0</td>\n      <td>0.001482</td>\n      <td>0.028740</td>\n      <td>0.001911</td>\n      <td>0.620885</td>\n      <td>0.087431</td>\n      <td>0.259551</td>\n    </tr>\n    <tr>\n      <th>167066</th>\n      <td>11137.0</td>\n      <td>11.0</td>\n      <td>0.000743</td>\n      <td>0.000828</td>\n      <td>0.000018</td>\n      <td>0.950585</td>\n      <td>0.001804</td>\n      <td>0.046022</td>\n    </tr>\n    <tr>\n      <th>167067</th>\n      <td>11137.0</td>\n      <td>12.0</td>\n      <td>0.000651</td>\n      <td>0.003874</td>\n      <td>0.000048</td>\n      <td>0.919886</td>\n      <td>0.003284</td>\n      <td>0.072257</td>\n    </tr>\n    <tr>\n      <th>167068</th>\n      <td>11137.0</td>\n      <td>13.0</td>\n      <td>0.000248</td>\n      <td>0.000262</td>\n      <td>0.000013</td>\n      <td>0.988694</td>\n      <td>0.002034</td>\n      <td>0.008749</td>\n    </tr>\n    <tr>\n      <th>167069</th>\n      <td>11137.0</td>\n      <td>14.0</td>\n      <td>0.000418</td>\n      <td>0.001253</td>\n      <td>0.000038</td>\n      <td>0.938457</td>\n      <td>0.022952</td>\n      <td>0.036882</td>\n    </tr>\n  </tbody>\n</table>\n<p>167070 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Get additional information to feed to the meta model\nlabels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\nmax_df = df.groupby(['training_instance'])[labels].agg('max').reset_index()\nmin_df = df.groupby(['training_instance'])[labels].agg('min').reset_index()\nmean_df = df.groupby(['training_instance'])[labels].agg('mean').reset_index()\nmedian_df = df.groupby(['training_instance'])[labels].agg('median').reset_index()\nstd_df = df.groupby(['training_instance'])[labels].agg('std').reset_index()\ndisplay(mean_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:24:57.890290Z","iopub.execute_input":"2024-03-14T18:24:57.891020Z","iopub.status.idle":"2024-03-14T18:24:57.993429Z","shell.execute_reply.started":"2024-03-14T18:24:57.890989Z","shell.execute_reply":"2024-03-14T18:24:57.992516Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"       training_instance   seizure       lpd       gpd      lrda      grda  \\\n0                    0.0  0.925391  0.011758  0.003779  0.018339  0.007754   \n1                    1.0  0.013179  0.011548  0.430501  0.007358  0.128501   \n2                    2.0  0.005435  0.048531  0.001314  0.817980  0.057258   \n3                    3.0  0.019544  0.013389  0.001033  0.833887  0.028320   \n4                    4.0  0.816041  0.007256  0.159430  0.000640  0.005497   \n...                  ...       ...       ...       ...       ...       ...   \n11133            11133.0  0.001761  0.008051  0.001109  0.001894  0.004193   \n11134            11134.0  0.003704  0.980797  0.001408  0.001236  0.000135   \n11135            11135.0  0.035923  0.416452  0.009732  0.100241  0.004969   \n11136            11136.0  0.005600  0.804470  0.003268  0.035733  0.004896   \n11137            11137.0  0.001611  0.006570  0.000636  0.840370  0.031735   \n\n          other  \n0      0.032979  \n1      0.408913  \n2      0.069482  \n3      0.103826  \n4      0.011136  \n...         ...  \n11133  0.982992  \n11134  0.012720  \n11135  0.432683  \n11136  0.146032  \n11137  0.119079  \n\n[11138 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_instance</th>\n      <th>seizure</th>\n      <th>lpd</th>\n      <th>gpd</th>\n      <th>lrda</th>\n      <th>grda</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.925391</td>\n      <td>0.011758</td>\n      <td>0.003779</td>\n      <td>0.018339</td>\n      <td>0.007754</td>\n      <td>0.032979</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.013179</td>\n      <td>0.011548</td>\n      <td>0.430501</td>\n      <td>0.007358</td>\n      <td>0.128501</td>\n      <td>0.408913</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.005435</td>\n      <td>0.048531</td>\n      <td>0.001314</td>\n      <td>0.817980</td>\n      <td>0.057258</td>\n      <td>0.069482</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.019544</td>\n      <td>0.013389</td>\n      <td>0.001033</td>\n      <td>0.833887</td>\n      <td>0.028320</td>\n      <td>0.103826</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>0.816041</td>\n      <td>0.007256</td>\n      <td>0.159430</td>\n      <td>0.000640</td>\n      <td>0.005497</td>\n      <td>0.011136</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11133</th>\n      <td>11133.0</td>\n      <td>0.001761</td>\n      <td>0.008051</td>\n      <td>0.001109</td>\n      <td>0.001894</td>\n      <td>0.004193</td>\n      <td>0.982992</td>\n    </tr>\n    <tr>\n      <th>11134</th>\n      <td>11134.0</td>\n      <td>0.003704</td>\n      <td>0.980797</td>\n      <td>0.001408</td>\n      <td>0.001236</td>\n      <td>0.000135</td>\n      <td>0.012720</td>\n    </tr>\n    <tr>\n      <th>11135</th>\n      <td>11135.0</td>\n      <td>0.035923</td>\n      <td>0.416452</td>\n      <td>0.009732</td>\n      <td>0.100241</td>\n      <td>0.004969</td>\n      <td>0.432683</td>\n    </tr>\n    <tr>\n      <th>11136</th>\n      <td>11136.0</td>\n      <td>0.005600</td>\n      <td>0.804470</td>\n      <td>0.003268</td>\n      <td>0.035733</td>\n      <td>0.004896</td>\n      <td>0.146032</td>\n    </tr>\n    <tr>\n      <th>11137</th>\n      <td>11137.0</td>\n      <td>0.001611</td>\n      <td>0.006570</td>\n      <td>0.000636</td>\n      <td>0.840370</td>\n      <td>0.031735</td>\n      <td>0.119079</td>\n    </tr>\n  </tbody>\n</table>\n<p>11138 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def df2tensor(df):\n    max_list = df[labels].values.tolist()\n    max_tensor = torch.tensor(max_list)\n    max_tensor.shape\n    return max_tensor\n\nmax_tensor = df2tensor(max_df)\nmin_tensor = df2tensor(min_df)\nmean_tensor = df2tensor(mean_df)\nmedian_tensor = df2tensor(median_df)\nstd_tensor = df2tensor(std_df)\nmean_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:24:58.746640Z","iopub.execute_input":"2024-03-14T18:24:58.747221Z","iopub.status.idle":"2024-03-14T18:24:58.921921Z","shell.execute_reply.started":"2024-03-14T18:24:58.747190Z","shell.execute_reply":"2024-03-14T18:24:58.920902Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 6])"},"metadata":{}}]},{"cell_type":"code","source":"def df2tensor_alldata(meta_df):\n    labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n    data = []\n\n    for i in range(int(meta_df['training_instance'].max()) + 1):\n        instance_data = []\n        instance_df = meta_df[meta_df['training_instance'] == i]\n\n        for j in range(len(instance_df)):\n            model_data = [instance_df.iloc[j][label] for label in labels]\n            instance_data.append(model_data)\n\n        data.append(instance_data)\n    data_tensor = torch.tensor(data)\n    return data_tensor\n\ninput_data = df2tensor_alldata(df)\ninput_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:06.047078Z","iopub.execute_input":"2024-03-14T18:26:06.047746Z","iopub.status.idle":"2024-03-14T18:26:51.081054Z","shell.execute_reply.started":"2024-03-14T18:26:06.047714Z","shell.execute_reply":"2024-03-14T18:26:51.080091Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 15, 6])"},"metadata":{}}]},{"cell_type":"code","source":"input_meta = torch.cat([max_tensor.unsqueeze(1), min_tensor.unsqueeze(1), \n                        mean_tensor.unsqueeze(1), std_tensor.unsqueeze(1), median_tensor.unsqueeze(1)], 1)\ninput_meta.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.082974Z","iopub.execute_input":"2024-03-14T18:26:51.083743Z","iopub.status.idle":"2024-03-14T18:26:51.122187Z","shell.execute_reply.started":"2024-03-14T18:26:51.083707Z","shell.execute_reply":"2024-03-14T18:26:51.121319Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 5, 6])"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")\ntrain_features = pd.DataFrame()\n\nfor label in labels:\n    train_grouped_by_spectrogram_id = train_df[f'{label}_vote'].groupby(train_df['spectrogram_id']).sum()\n\n    label_vote_sum = pd.DataFrame()\n    label_vote_sum[\"spectrogram_id\"] = train_grouped_by_spectrogram_id.index\n    label_vote_sum[f\"{label}_vote_sum\"] = train_grouped_by_spectrogram_id.values\n\n    if label == labels[0]:\n        train_features = label_vote_sum\n    else:\n        train_features = train_features.merge(label_vote_sum, on='spectrogram_id', how='left')\n\n# Add a column to sum all votes\ntrain_features['total_vote'] = 0\nfor label in labels:\n    train_features['total_vote'] += train_features[f'{label}_vote_sum']\n\n# Calculate and store the normalized vote for each label\nfor label in labels:\n    train_features[f'{label}_vote'] = train_features[f'{label}_vote_sum'] / train_features['total_vote']\n\n# Select relevant columns for the training features\nchoose_cols = ['spectrogram_id']\nfor label in labels:\n    choose_cols += [f'{label}_vote']\ntrain_features = train_features[choose_cols]\n\n# Add a column with the path to the spectrogram files\ntrain_features['path'] = train_features['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\" + str(x) + \".parquet\")\n\nlabels_meta = train_features[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].values.tolist()\nlabels_meta_tensor = torch.tensor(labels_meta)\nlabels_meta_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.123552Z","iopub.execute_input":"2024-03-14T18:26:51.124057Z","iopub.status.idle":"2024-03-14T18:26:51.464120Z","shell.execute_reply.started":"2024-03-14T18:26:51.124025Z","shell.execute_reply":"2024-03-14T18:26:51.463106Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 6])"},"metadata":{}}]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_size):\n        super(MLP, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_size*6, 600),\n            nn.ReLU(),\n            nn.Linear(600, 1200),\n            nn.ReLU(),\n            nn.Linear(1200, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 600),\n            nn.ReLU(),\n            nn.Linear(600, 6),\n            nn.Softmax(1)\n        )\n        \n    def forward(self, x):\n        # convert tensor (64, 20, 6) --> (64, 20*6)\n        x = x.view(x.size(0), -1)\n        x = self.layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.466136Z","iopub.execute_input":"2024-03-14T18:26:51.466426Z","iopub.status.idle":"2024-03-14T18:26:51.473383Z","shell.execute_reply.started":"2024-03-14T18:26:51.466400Z","shell.execute_reply":"2024-03-14T18:26:51.472533Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class KLDivergenceLoss(nn.Module):\n    def __init__(self, epsilon=1e-15):\n        super(KLDivergenceLoss, self).__init__()\n        self.epsilon = epsilon\n\n    def forward(self, p, q):\n        # Clip probabilities to avoid log(0)\n        p = torch.clamp(p, self.epsilon, 1 - self.epsilon)\n\n        # Compute logarithms\n        log_p = torch.log(p)\n        log_q = nn.functional.log_softmax(q, dim=1)\n\n        # Calculate element-wise KL divergence\n        kl_divergence_per_point = p * (log_p - log_q)\n\n        # Sum over classes to get KL divergence per sample\n        kl_divergence_per_sample = torch.sum(kl_divergence_per_point, dim=1)\n\n        # Compute mean over samples\n        kl_loss = torch.mean(kl_divergence_per_sample)\n\n        return kl_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.474596Z","iopub.execute_input":"2024-03-14T18:26:51.474889Z","iopub.status.idle":"2024-03-14T18:26:51.489347Z","shell.execute_reply.started":"2024-03-14T18:26:51.474855Z","shell.execute_reply":"2024-03-14T18:26:51.488342Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport sys\n\ndef train_mlp(input_tensor, target_tensor, model, criterion_ce, criterion_kl, optimizer, batch_size=32, num_epochs=10, validation_size=0.1,lambda_=1):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    # Split data into training and validation sets\n    total_size = len(input_tensor)\n    val_size = int(total_size * validation_size)\n    train_size = total_size - val_size\n    \n    train_indices = torch.randperm(train_size)\n    val_indices = torch.arange(train_size, total_size)\n    \n    train_input = input_tensor[train_indices].to(device)\n    train_target = target_tensor[train_indices].to(device)\n    \n    val_input = input_tensor[val_indices].to(device)\n    val_target = target_tensor[val_indices].to(device)\n    \n    best_total_loss = sys.maxsize\n    not_improved_counter = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_ce_loss = 0.0\n        running_kl_loss = 0.0\n        tel = 0\n        \n        # Shuffle indices for training\n        indices = torch.randperm(train_size)\n        \n        # Iterate over batches for training\n        for i in range(0, len(indices), batch_size):\n            batch_indices = indices[i:i+batch_size]\n            \n            inputs = train_input[batch_indices]\n            targets = train_target[batch_indices]\n\n            # Forward pass\n            outputs = model(inputs)\n            ce_loss = criterion_ce(outputs, targets)\n            kl_loss = criterion_kl(targets, outputs)\n\n            # Combined loss\n            total_loss = ce_loss + lambda_ * kl_loss\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n\n            running_ce_loss += ce_loss.item()\n            running_kl_loss += kl_loss.item()\n            tel += 1\n\n        average_ce_loss = running_ce_loss / tel\n        average_kl_loss = running_kl_loss / tel\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], CE Loss: {average_ce_loss:.4f}, KL Loss: {average_kl_loss:.4f}\")\n        \n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_outputs = model(val_input)\n            val_ce_loss = criterion_ce(val_outputs, val_target)\n            val_accuracy = accuracy(val_outputs, val_target)\n            val_kl_loss = criterion_kl(val_outputs, val_target)\n            val_total_loss = val_ce_loss + lambda_ * val_kl_loss\n            \n        if val_total_loss < best_total_loss:\n            torch.save(model.state_dict(), 'meta_model_best.pth')\n            best_total_loss = val_total_loss\n            print(f\"Model saved on epoch: {epoch} with total loss: {best_total_loss} and accuracy: {val_accuracy}\")\n            not_improved_counter = 0\n        else:\n            not_improved_counter += 1\n        if not_improved_counter >= 20:\n            break\n\ndef accuracy(outputs, targets):\n    _, predicted = torch.max(outputs, 1)\n    _, label = torch.max(targets, 1)\n    correct = (predicted == label).sum().item()\n    total = targets.size(0)\n    return correct / total\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.491419Z","iopub.execute_input":"2024-03-14T18:26:51.491736Z","iopub.status.idle":"2024-03-14T18:26:51.507326Z","shell.execute_reply.started":"2024-03-14T18:26:51.491712Z","shell.execute_reply":"2024-03-14T18:26:51.506467Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_tensor = input_meta.float().to(device)\nprint(input_tensor.shape)\nlabels_meta_tensor = labels_meta_tensor.float().to(device)\n\nmeta_model = MLP(input_tensor.shape[1]).to(device)\n\noptimizer = torch.optim.Adam(meta_model.parameters(), lr=0.001)\nloss_ce = nn.CrossEntropyLoss()\nloss_bce = nn.BCELoss()\nloss_kl = KLDivergenceLoss()","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:51.508603Z","iopub.execute_input":"2024-03-14T18:26:51.508871Z","iopub.status.idle":"2024-03-14T18:26:54.957599Z","shell.execute_reply.started":"2024-03-14T18:26:51.508849Z","shell.execute_reply":"2024-03-14T18:26:54.956783Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"torch.Size([11138, 5, 6])\n","output_type":"stream"}]},{"cell_type":"code","source":"meta_model","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:07:23.718220Z","iopub.execute_input":"2024-03-14T13:07:23.718590Z","iopub.status.idle":"2024-03-14T13:07:23.726093Z","shell.execute_reply.started":"2024-03-14T13:07:23.718565Z","shell.execute_reply":"2024-03-14T13:07:23.725279Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"MLP(\n  (layers): Sequential(\n    (0): Linear(in_features=30, out_features=600, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=600, out_features=1200, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=1200, out_features=1000, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=1000, out_features=600, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=600, out_features=6, bias=True)\n    (9): Softmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"mean_tensor.unsqueeze(1).shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:25:13.276063Z","iopub.execute_input":"2024-03-14T18:25:13.276665Z","iopub.status.idle":"2024-03-14T18:25:13.304118Z","shell.execute_reply.started":"2024-03-14T18:25:13.276632Z","shell.execute_reply":"2024-03-14T18:25:13.303264Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 1, 6])"},"metadata":{}}]},{"cell_type":"code","source":"labels_meta_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:26:54.958659Z","iopub.execute_input":"2024-03-14T18:26:54.959047Z","iopub.status.idle":"2024-03-14T18:26:54.964468Z","shell.execute_reply.started":"2024-03-14T18:26:54.959022Z","shell.execute_reply":"2024-03-14T18:26:54.963577Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([11138, 6])"},"metadata":{}}]},{"cell_type":"code","source":"print(loss_kl(mean_tensor.to(device),labels_meta_tensor))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:32:18.652340Z","iopub.execute_input":"2024-03-14T18:32:18.652715Z","iopub.status.idle":"2024-03-14T18:32:18.659700Z","shell.execute_reply.started":"2024-03-14T18:32:18.652687Z","shell.execute_reply":"2024-03-14T18:32:18.658947Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"tensor(0.6482, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"train_mlp(input_tensor, labels_meta_tensor, meta_model, loss_ce, loss_kl, optimizer, batch_size=64, num_epochs=80, validation_size=0.1, lambda_=2)\ntorch.save(meta_model.state_dict(), 'meta_model_final.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:28:50.886230Z","iopub.execute_input":"2024-03-14T18:28:50.886646Z","iopub.status.idle":"2024-03-14T18:29:28.126409Z","shell.execute_reply.started":"2024-03-14T18:28:50.886617Z","shell.execute_reply":"2024-03-14T18:29:28.125395Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch [1/80], CE Loss: 1.2759, KL Loss: 0.9034\nModel saved on epoch: 0 with total loss: 3.5981764793395996 and accuracy: 0.9299191374663073\nEpoch [2/80], CE Loss: 1.2212, KL Loss: 0.8485\nEpoch [3/80], CE Loss: 1.2202, KL Loss: 0.8474\nEpoch [4/80], CE Loss: 1.2199, KL Loss: 0.8471\nModel saved on epoch: 3 with total loss: 3.5908422470092773 and accuracy: 0.9281221922731356\nEpoch [5/80], CE Loss: 1.2182, KL Loss: 0.8454\nModel saved on epoch: 4 with total loss: 3.565169334411621 and accuracy: 0.9299191374663073\nEpoch [6/80], CE Loss: 1.2180, KL Loss: 0.8455\nModel saved on epoch: 5 with total loss: 3.549095630645752 and accuracy: 0.9353099730458221\nEpoch [7/80], CE Loss: 1.2175, KL Loss: 0.8446\nEpoch [8/80], CE Loss: 1.2170, KL Loss: 0.8441\nModel saved on epoch: 7 with total loss: 3.5357446670532227 and accuracy: 0.9380053908355795\nEpoch [9/80], CE Loss: 1.2167, KL Loss: 0.8441\nEpoch [10/80], CE Loss: 1.2171, KL Loss: 0.8444\nModel saved on epoch: 9 with total loss: 3.5114283561706543 and accuracy: 0.9263252470799641\nEpoch [11/80], CE Loss: 1.2163, KL Loss: 0.8434\nEpoch [12/80], CE Loss: 1.2162, KL Loss: 0.8435\nEpoch [13/80], CE Loss: 1.2156, KL Loss: 0.8429\nEpoch [14/80], CE Loss: 1.2157, KL Loss: 0.8430\nEpoch [15/80], CE Loss: 1.2163, KL Loss: 0.8436\nEpoch [16/80], CE Loss: 1.2158, KL Loss: 0.8435\nEpoch [17/80], CE Loss: 1.2168, KL Loss: 0.8438\nEpoch [18/80], CE Loss: 1.2156, KL Loss: 0.8428\nEpoch [19/80], CE Loss: 1.2158, KL Loss: 0.8429\nModel saved on epoch: 18 with total loss: 3.498417377471924 and accuracy: 0.9254267744833783\nEpoch [20/80], CE Loss: 1.2154, KL Loss: 0.8428\nEpoch [21/80], CE Loss: 1.2155, KL Loss: 0.8424\nEpoch [22/80], CE Loss: 1.2150, KL Loss: 0.8422\nEpoch [23/80], CE Loss: 1.2152, KL Loss: 0.8423\nEpoch [24/80], CE Loss: 1.2156, KL Loss: 0.8431\nModel saved on epoch: 23 with total loss: 3.4917285442352295 and accuracy: 0.9433962264150944\nEpoch [25/80], CE Loss: 1.2149, KL Loss: 0.8421\nModel saved on epoch: 24 with total loss: 3.487666130065918 and accuracy: 0.9398023360287511\nEpoch [26/80], CE Loss: 1.2151, KL Loss: 0.8424\nEpoch [27/80], CE Loss: 1.2144, KL Loss: 0.8417\nEpoch [28/80], CE Loss: 1.2146, KL Loss: 0.8418\nEpoch [29/80], CE Loss: 1.2145, KL Loss: 0.8417\nEpoch [30/80], CE Loss: 1.2143, KL Loss: 0.8415\nEpoch [31/80], CE Loss: 1.2148, KL Loss: 0.8419\nEpoch [32/80], CE Loss: 1.2149, KL Loss: 0.8422\nEpoch [33/80], CE Loss: 1.2142, KL Loss: 0.8415\nEpoch [34/80], CE Loss: 1.2142, KL Loss: 0.8412\nModel saved on epoch: 33 with total loss: 3.4770050048828125 and accuracy: 0.9335130278526504\nEpoch [35/80], CE Loss: 1.2140, KL Loss: 0.8414\nModel saved on epoch: 34 with total loss: 3.4750571250915527 and accuracy: 0.9317160826594789\nEpoch [36/80], CE Loss: 1.2142, KL Loss: 0.8414\nEpoch [37/80], CE Loss: 1.2144, KL Loss: 0.8414\nEpoch [38/80], CE Loss: 1.2142, KL Loss: 0.8413\nEpoch [39/80], CE Loss: 1.2140, KL Loss: 0.8414\nEpoch [40/80], CE Loss: 1.2141, KL Loss: 0.8412\nEpoch [41/80], CE Loss: 1.2137, KL Loss: 0.8410\nEpoch [42/80], CE Loss: 1.2137, KL Loss: 0.8407\nEpoch [43/80], CE Loss: 1.2138, KL Loss: 0.8410\nEpoch [44/80], CE Loss: 1.2135, KL Loss: 0.8405\nEpoch [45/80], CE Loss: 1.2135, KL Loss: 0.8407\nEpoch [46/80], CE Loss: 1.2136, KL Loss: 0.8409\nEpoch [47/80], CE Loss: 1.2135, KL Loss: 0.8407\nEpoch [48/80], CE Loss: 1.2134, KL Loss: 0.8405\nEpoch [49/80], CE Loss: 1.2137, KL Loss: 0.8409\nEpoch [50/80], CE Loss: 1.2136, KL Loss: 0.8407\nModel saved on epoch: 49 with total loss: 3.4742250442504883 and accuracy: 0.9398023360287511\nEpoch [51/80], CE Loss: 1.2134, KL Loss: 0.8407\nEpoch [52/80], CE Loss: 1.2138, KL Loss: 0.8409\nEpoch [53/80], CE Loss: 1.2138, KL Loss: 0.8409\nEpoch [54/80], CE Loss: 1.2133, KL Loss: 0.8408\nEpoch [55/80], CE Loss: 1.2131, KL Loss: 0.8402\nModel saved on epoch: 54 with total loss: 3.4724626541137695 and accuracy: 0.9389038634321654\nEpoch [56/80], CE Loss: 1.2132, KL Loss: 0.8404\nEpoch [57/80], CE Loss: 1.2132, KL Loss: 0.8404\nModel saved on epoch: 56 with total loss: 3.4714183807373047 and accuracy: 0.945193171608266\nEpoch [58/80], CE Loss: 1.2128, KL Loss: 0.8404\nEpoch [59/80], CE Loss: 1.2131, KL Loss: 0.8405\nEpoch [60/80], CE Loss: 1.2128, KL Loss: 0.8399\nEpoch [61/80], CE Loss: 1.2129, KL Loss: 0.8399\nEpoch [62/80], CE Loss: 1.2133, KL Loss: 0.8403\nEpoch [63/80], CE Loss: 1.2129, KL Loss: 0.8400\nEpoch [64/80], CE Loss: 1.2127, KL Loss: 0.8398\nModel saved on epoch: 63 with total loss: 3.4556641578674316 and accuracy: 0.9424977538185085\nEpoch [65/80], CE Loss: 1.2126, KL Loss: 0.8398\nEpoch [66/80], CE Loss: 1.2129, KL Loss: 0.8400\nEpoch [67/80], CE Loss: 1.2126, KL Loss: 0.8399\nEpoch [68/80], CE Loss: 1.2124, KL Loss: 0.8398\nModel saved on epoch: 67 with total loss: 3.4528889656066895 and accuracy: 0.9442946990116802\nEpoch [69/80], CE Loss: 1.2127, KL Loss: 0.8399\nEpoch [70/80], CE Loss: 1.2130, KL Loss: 0.8401\nEpoch [71/80], CE Loss: 1.2128, KL Loss: 0.8399\nEpoch [72/80], CE Loss: 1.2125, KL Loss: 0.8397\nEpoch [73/80], CE Loss: 1.2124, KL Loss: 0.8395\nEpoch [74/80], CE Loss: 1.2124, KL Loss: 0.8397\nEpoch [75/80], CE Loss: 1.2134, KL Loss: 0.8406\nEpoch [76/80], CE Loss: 1.2127, KL Loss: 0.8399\nEpoch [77/80], CE Loss: 1.2123, KL Loss: 0.8397\nEpoch [78/80], CE Loss: 1.2123, KL Loss: 0.8396\nEpoch [79/80], CE Loss: 1.2121, KL Loss: 0.8394\nEpoch [80/80], CE Loss: 1.2121, KL Loss: 0.8395\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    output = meta_model(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:30:01.582891Z","iopub.execute_input":"2024-03-14T18:30:01.583240Z","iopub.status.idle":"2024-03-14T18:30:01.590224Z","shell.execute_reply.started":"2024-03-14T18:30:01.583215Z","shell.execute_reply":"2024-03-14T18:30:01.589313Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(loss_kl(output,labels_meta_tensor))","metadata":{"execution":{"iopub.status.busy":"2024-03-14T18:30:02.616736Z","iopub.execute_input":"2024-03-14T18:30:02.617513Z","iopub.status.idle":"2024-03-14T18:30:02.624073Z","shell.execute_reply.started":"2024-03-14T18:30:02.617478Z","shell.execute_reply":"2024-03-14T18:30:02.623120Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tensor(1.1249, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1.1502 input, mean, std\n1.1211 max, min, mean, std, median\n1.1325 input, max, min, mean, std, median\nCurrent version: max, min, mean, std, median","metadata":{}}]}